{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyP3EJg9kI8w5g3167Ul182j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/ENCS5141-INTELLIGENT-SYSTEMS-LAB/blob/main/ENCS5141_Exp2_Handling_Missing_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experiment #2: Data Visualization and Data Cleaning\n",
        "\n",
        "This experiment focuses on discussing concepts and implementing code snippets to demonstrate various techniques used for data cleaning as part of an Exploratory Data Analysis (EDA). EDA plays a crucial role in comprehending and examining datasets. Throughout the experiment, you will also need to solve a few exercises to demonstrate your comprehension and acquire the necessary skills. The topics that will be discussed in the experiment are\n",
        "##2.1 Data Visualization\n",
        "2.1.1 Using Matplotlib \\\n",
        "2.1.2 Using Seaborn \\\n",
        "2.1.3 Using Pandas \\\n",
        "2.1.4 Boxplot \\\n",
        "##2.2 Descriptive statistics\n",
        "2.2.1 Central Tendency \\\n",
        "2.2.2 Variation \\\n",
        "2.2.3 Shape of Distribution \\\n",
        "2.2.4 Quantiles \\\n",
        "##2.3 Handling Missing Data\n",
        "2.3.1 Missing Numeric Data \\\n",
        "2.3.2 Missing Categorical Data \\\n",
        "##2.4 Handling Outliers\n",
        "2.4.1 Statistical Outlier Detection Using Z-Score \\\n",
        "2.4.2 Using Interquartile Range and Boxplots \\\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "O9hpxolNxS2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.1. Data Visualization\n"
      ],
      "metadata": {
        "id": "CeUpqnQXRAvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1.1 Using Matplotlib\n",
        "Matplotlib package is an open source library that is used to create professional figures and plots. To make a plot, you need first to import the **pyplot** sub-module and then use the **plot** method with proper arguments."
      ],
      "metadata": {
        "id": "qgx9TYqdoW63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# generating a sinwwave signal\n",
        "t = np.arange(0, 1, 0.001)\n",
        "sig = np.sin(2 * np.pi * 2 * t)\n",
        "\n",
        "plt.plot(t,sig)\n",
        "plt.xlabel('Time (sec)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RfkuUIfERAP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Matplotlib** package can also be used to plot multiple axes in the same figure or two curves on the same axis."
      ],
      "metadata": {
        "id": "2v2MnhptUbeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generating two sinwwave signals\n",
        "t = np.arange(0, 2, 0.001)\n",
        "sig1 = np.sin(2 * np.pi * 2 * t)\n",
        "sig2 = np.sin(2 * np.pi * 2 * t - np.pi/6)\n",
        "sig3 = np.sin(2 * np.pi * 2 * t + np.pi/4)\n",
        "\n",
        "fig, axs = plt.subplots(2, 1)\n",
        "axs[0].plot(t, sig1)\n",
        "axs[0].set_xlim(0, 2)\n",
        "axs[0].set_xlabel('Time (sec)')\n",
        "axs[0].set_ylabel('Amplitude')\n",
        "axs[0].grid(True)\n",
        "\n",
        "axs[1].plot(t, sig2, t, sig3)\n",
        "axs[1].set_xlim(0, 2)\n",
        "axs[1].set_xlabel('Time (sec)')\n",
        "axs[1].set_ylabel('Amplitude')\n",
        "axs[1].grid(True)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zWl7mh7MUiEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.1**: Refer to the matplot documentation at https://matplotlib.org/stable/gallery/color/named_colors.html to plot two curves in the same figure, add markers of specific size, add a legend, and add a figure title."
      ],
      "metadata": {
        "id": "0P1KcwMtSzSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write you code here\n"
      ],
      "metadata": {
        "id": "M8Z7g3cpYzSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.2**: Create two axes next to each other, and plot a sinwave in one axis and a cosine wave on the other. Add markers, legend, and a title for the figure."
      ],
      "metadata": {
        "id": "qhppNcuyW98e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write you code here\n"
      ],
      "metadata": {
        "id": "GfTp52lqY2tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##2.1.2 Using Seaborn\n",
        "Seaborn is a data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. To make a plot, you need first to import the **sns** sub-module and then use a specific method with proper arguments. For example you may use the **relplot** method to create relational plots."
      ],
      "metadata": {
        "id": "epEqA2TGX-xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# generating a sinwwave signal\n",
        "t = np.arange(0, 1, 0.001)\n",
        "sin = np.sin(2 * np.pi * 2 * t)\n",
        "cos = np.cos(2 * np.pi * 2 * t)\n",
        "\n",
        "#Creating a dataframe from the time, sin, and cos curves\n",
        "df = pd.DataFrame({'time':t, 'sin':sin, 'cos':cos})\n",
        "\n",
        "# Create a visualization\n",
        "sns.relplot(data=df,kind=\"line\",x=\"time\",y=\"sin\").set(title='Sinwave')"
      ],
      "metadata": {
        "id": "pzHgCPxj4Nmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use the **relplot** function to create more advanced visualizations of your data. For instance, let's take the \"tips\" dataset as an example. This dataset contains information about tips received by a waiter over a few months in a restaurant. It has details like how much tip was given, the bill amount, whether the person paying the bill is male or female, if there were smokers in the group, the day of the week, the time of day, and the size of the group. To import the dataset use the following code"
      ],
      "metadata": {
        "id": "JEC0igG1FN6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an example dataset\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "tips.info()"
      ],
      "metadata": {
        "id": "hrkK8xWf7znI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the following code to view the first 10 rows in the dataset"
      ],
      "metadata": {
        "id": "w1wQvyLBHF8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tips.head()"
      ],
      "metadata": {
        "id": "h9H2zus1HD7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the **relplot()** method helps us understand patterns in the dataset how different factors might be connected."
      ],
      "metadata": {
        "id": "9WUT7tGmGlhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a visualization\n",
        "sns.relplot(data=tips,\n",
        "    x=\"total_bill\", y=\"tip\", col=\"time\",\n",
        "    hue=\"smoker\", style=\"smoker\", size=\"size\",\n",
        ")"
      ],
      "metadata": {
        "id": "orIQqAkj78VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From observing the visualization of the tips dataset, we can infer that as the total bill size grows, the tip value tends to increase proportionally. Additionally, it's apparent that both the total bill and tip value are higher when the group size is larger. **Can you observe any other patterns?**"
      ],
      "metadata": {
        "id": "DLhe12ulH1XP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.3**: Load a dataset from the sns repository and then use the **relplot()** method to visualize and understand patterns in the dataset. You may list the datasets in the sns repository using the **sns.get_dataset_names()** method."
      ],
      "metadata": {
        "id": "iqSms4zuMgJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write you code here\n"
      ],
      "metadata": {
        "id": "fpEmSnZfN1Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **histplot()** is another method in the **sns** submodule that can be used to plot univariate or bivariate histograms to show distributions of datasets."
      ],
      "metadata": {
        "id": "mcJwy388KeE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(figsize=(16, 4),ncols=3)\n",
        "\n",
        "#Create histograms displaying the distribution of tip values\n",
        "sns.histplot(data=tips, x=\"tip\", ax=axs[0])\n",
        "\n",
        "#Create histograms displaying the distribution of tip values based on the time of day\n",
        "sns.histplot(data=tips, x=\"tip\", hue=\"time\",ax=axs[1])\n",
        "\n",
        "#Create histograms displaying the distribution of tip values based on the time of day, and incorporate the actual distribution curve.\n",
        "sns.histplot(data=tips, x=\"tip\", hue=\"time\",ax=axs[2], kde=True)"
      ],
      "metadata": {
        "id": "YGHY8yc1KBHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.4**: Create a histogram plot for the dataset you loaded in task 2.3 and incorporate the actual distribution curve."
      ],
      "metadata": {
        "id": "Ygl_-2kGN4t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write you code here\n"
      ],
      "metadata": {
        "id": "Pam0Kol2N4BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.5**: Use the **scatterplot()** method within the **sns** submodule and the **subplots()** method within the **matplotlib** submodule to generate visual representations for the dataset you loaded in step 2.3."
      ],
      "metadata": {
        "id": "KuWQRpWYRcWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write you code here\n"
      ],
      "metadata": {
        "id": "D8-UGkshR53b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1.3 Using Pandas\n",
        "Data visualization using pandas is a common task in data analysis and manipulation. As explained in experiment #1, pandas provides an easy-to-use DataFrame structure that allows you to store, manipulate, and analyze data efficiently. When combined with data visualization libraries like Matplotlib or Seaborn, pandas can generate a wide range of visualizations to explore and communicate insights from your data. In this section, we will present few types of visualizations that can be created using pandas."
      ],
      "metadata": {
        "id": "xbMyQsI83JZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Category': ['Fruits','Fruits','Fruits','Fruits','Fruits', 'Vegetables','Vegetables','Vegetables','Vegetables','Vegetables','Grains','Grains','Grains'],\n",
        "    'Item': ['Apple', 'Banana', 'Orange', 'Mango', 'Grapes', 'Spinach', 'Tomato', 'Cucumber','Cauliflower','Eggplant','Rice', 'Wheat', 'Corn'],\n",
        "    'Weight': [200, 150, 250, 150, 200, 120, 200, 120, 120, 250, 120, 300, 300],\n",
        "    'Cost': [0.5, 0.3, 0.2, 2.5, 1.0, 1.5, 0.3, 0.3, 0.5, 1.2, 1.6, 0.8, 0.5],\n",
        "    'Calories': [95, 23, 205, 335, 120, 33, 50, 250, 350, 300, 420, 200, 250]\n",
        "}\n",
        "\n",
        "\n",
        "food = pd.DataFrame(data)\n",
        "food.head()"
      ],
      "metadata": {
        "id": "7pAXMkqO3cTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Line Plot**: To create a line plot, you can use the **plot()** method on the DataFrame."
      ],
      "metadata": {
        "id": "-NNOH_5s3jzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "food.plot(x='Weight', y='Cost', kind='line', color='red')\n",
        "plt.xlabel('Weight')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Line Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BQnXrEic33uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scatter Plot**: To create a scatter plot use the **plot()** method with **kind='scatter'**."
      ],
      "metadata": {
        "id": "-rQaamEr47Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food.plot(x='Weight', y='Cost', kind='scatter')\n",
        "plt.xlabel('Weight')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Scatter Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wywDQWLJ4-oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Histogram**: To create a histogram use the **plot()** method with **kind='hist'**."
      ],
      "metadata": {
        "id": "0Mcuh2_V5GjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food['Cost'].plot(kind='hist', bins=10)\n",
        "plt.xlabel('Cost')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aZTZRaSj5HOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bar Plot**: To create a bar plot use the **plot()** method with **kind='bar'**."
      ],
      "metadata": {
        "id": "ywNe6QYC5dpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food.plot(x='Weight', y='Cost', kind='bar')\n",
        "plt.xlabel('Weight')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Bar Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XktH-ybF5eXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also utilize the **groupby()** function along with the **plot()** function with the **kind='bar'** option to aggregate column values and generate insightful bar visualizations."
      ],
      "metadata": {
        "id": "WCSJqi9t6d2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by 'Category' and summing 'Cost'\n",
        "grouped_data = food.groupby('Category')['Cost'].sum()\n",
        "\n",
        "# Creating a bar plot\n",
        "grouped_data.plot(kind='bar')\n",
        "plt.xlabel('Product Category')\n",
        "plt.ylabel('Total Sales Amount')\n",
        "plt.title('Total Sales Amount by Product Category')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AQMzb6rB6vJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.7**: Create a histogram for the food weights in the Food DataFrame defined in this section."
      ],
      "metadata": {
        "id": "-fDg2Vb0AT-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write you code here\n"
      ],
      "metadata": {
        "id": "kyyePadvBEeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.8**: Generate informative bar charts illustrating the calorie distribution across food categories using the Food DataFrame introduced in this section."
      ],
      "metadata": {
        "id": "h71DGLEoBGeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write you code here\n"
      ],
      "metadata": {
        "id": "dtdrJ8E_BIbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1.4 Boxplot"
      ],
      "metadata": {
        "id": "wu8ys7wDlXCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A boxplot is a graphical representation that provides insights into the distribution and variability of data. It help us visualize the spread and central tendency of the data. In a boxplot, a rectangular \"box\" is drawn to represent the interquartile range (IQR), which spans from the first quartile (Q1) to the third quartile (Q3) of the data. The first quartile (Q1) represents the point where a quarter (25%) of the data values fall below when arranged in increasing order. On the other hand, the third quartile (Q3), marks the threshold beneath which three-quarters (75%) of the data values are situated when organized in increasing order."
      ],
      "metadata": {
        "id": "26YP8_o-lKbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The boxplot can be created using the **boxplot()** method within the **panda** package (panada DataFrame)."
      ],
      "metadata": {
        "id": "XPy2umIamdBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tips.boxplot(by ='day', column =['total_bill'], grid = False)"
      ],
      "metadata": {
        "id": "j5W6lvqFmn1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The boxplot can also be generated using the **boxplot()** method within the **sns** submodule."
      ],
      "metadata": {
        "id": "ZSinC8BkmonZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x = 'day', y = 'total_bill', data = tips)"
      ],
      "metadata": {
        "id": "cBYQCH76mpCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.9**: Use the **boxplot()** method within the **sns** submodule to generate boxplot for the dataset you loaded in step 2.3."
      ],
      "metadata": {
        "id": "rc-hO9ownzIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write you code here\n"
      ],
      "metadata": {
        "id": "v3eauRDIn0iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R8IRLTghtXKS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P8hP-j57tVpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.2 Descriptive statistics\n",
        "Descriptive statistics involves analyzing and summarizing data to gain insights into its central tendencies, variability, and overall distribution. It playes a crucial role in machine learning for many reasons including data understanding and exploration and data cleaning and preprocessing. In data understanding and exploration, descriptive statistics provide an initial overview of the dataset, helping you understand its distribution, central tendencies, and variability. This exploration phase is vital for identifying data patterns, anomalies, and potential issues that might impact the quality of your machine learning models. While in data cleaning and preprocessing, descriptive statistics help you identify missing values, outliers, and inconsistencies that need to be addressed. Cleaning and preprocessing ensure that your model receives accurate and reliable input data."
      ],
      "metadata": {
        "id": "LwOUX2z0uxrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.1 Central Tendency\n",
        "Mean: The average value of the data.\n",
        "Median: The middle value when the data is sorted.\n",
        "Mode: The value that appears most frequently in the data."
      ],
      "metadata": {
        "id": "lgk-YRqSwJ7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.2 Variation\n",
        "Variance: A measure of how much the data points deviate from the mean.\n",
        "Standard Deviation: The square root of the variance, indicating the spread of data."
      ],
      "metadata": {
        "id": "pgfgXhCowOJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.3 Shape of Distribution\n",
        "Skewness: Measures the asymmetry of the data distribution.\n",
        "Kurtosis: Measures the peakedness of the data distribution."
      ],
      "metadata": {
        "id": "JRbRqzb8wPMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.4 Quantiles\n",
        "Percentiles: Values below which a given percentage of data falls.\n",
        "Interquartile Range (IQR): The range between the 25th and 75th percentiles.\n",
        "Pandas provides functions like mean(), median(), mode(), std(), var(), min(), max(), quantile(), and more to calculate these descriptive statistics. These functions can be applied to entire DataFrames, specific columns, or Series."
      ],
      "metadata": {
        "id": "6kSUL6Ewybb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.2. Handling Missing Data\n"
      ],
      "metadata": {
        "id": "b3uSipo2oOLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2.1 Missing numeric data"
      ],
      "metadata": {
        "id": "KvF4i01yzPZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Km7MUso8oYzU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bVWdgQP0pVHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXPLORATORY DATA ANALYSIS – DATA CLEANING"
      ],
      "metadata": {
        "id": "mkRHIvM06yZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will demonstrate Data Cleaning as part of Exploratory Data Analysis (EDA). We will work on a modified version of the cardiovascular dataset from Kaggle (https://www.kaggle.com/code/sulianova/eda-cardiovascular-data/data). The dataset consists of 70000 records of patient data in 12 features. The target class \"cardio\" equals 1, when a patient has cardiovascular disease, and it's 0 if a patient is healthy."
      ],
      "metadata": {
        "id": "-DapbW18f-Zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "DcZDdukne9go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to import some libraries that will be used during data cleaning."
      ],
      "metadata": {
        "id": "p8IHjsB_NJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import rcParams\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LXO2d36eNJSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "y3w73IED3CyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Clone the dataset Repository***\n",
        "\n",
        "The modified dataset can be cloned from the GitHub repository https://github.com/mkjubran/AIData.git as below"
      ],
      "metadata": {
        "id": "YkNaY9Pl3Tfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./AIData\n",
        "!git clone https://github.com/mkjubran/AIData.git"
      ],
      "metadata": {
        "id": "Q913_8qtKfPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Read the dataset***\n",
        "\n",
        "The data is stored in the cardio_train.csv file. Read the input data into a dataframe using the Pandas library (https://pandas.pydata.org/) to read the data."
      ],
      "metadata": {
        "id": "FYe9U8mrMcqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/AIData/cardio_train_modified.csv\",sep=\";\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LdJFnrziMdl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Display Data Info and Check NAN***\n",
        "\n",
        "To display the content of the data and type of features use the info() method"
      ],
      "metadata": {
        "id": "Ea4lRShuYjBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "y2UGE3RsYoLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the dataframe consists of 70000 rows with 12 variables (features). Ten features are numerical and two features are objects (gender, smoke). We notice that for some of the features the number of non-null values does not equal 70000 which means that some feature values in the data are missing.\n",
        "\n",
        "We can get the exact number of missing values for each feature using the isnull() method as below"
      ],
      "metadata": {
        "id": "HhqXkiZra8PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "kXV9LNxccgFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also get the number and percentage of patients' records that has one or more missing values"
      ],
      "metadata": {
        "id": "49UJsVbZ48ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().any(axis=1).sum())\n",
        "print(100*df.isnull().any(axis=1).sum()/df.shape[0],'%')"
      ],
      "metadata": {
        "id": "BR5M6mwW4873"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To display the records with NAN values"
      ],
      "metadata": {
        "id": "XRh5km2u7hzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.isnull().any(axis=1)]"
      ],
      "metadata": {
        "id": "sYLytc857Yp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "tizgKxAHRl5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: drop all empty records**"
      ],
      "metadata": {
        "id": "sNpavSHHRsBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is usually to drop all empty records. I.e. records with all features are NaN."
      ],
      "metadata": {
        "id": "slsyL5n6B5e-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(how='all', inplace=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "IRj5nkzjC31b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By comparing the number of NaN features before and after the last step, we notice that there were 3 empty records in the dataset. We notice also that the number of missing values for the features 'weight', 'ap_hi', ap_lo', and 'gluc' is very low. So the best choice is to delete these patients' records from the dataset."
      ],
      "metadata": {
        "id": "DI_uEUsMDWRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: target feature (class, label)**\n",
        "\n",
        "The target feature (class, label) \"cardio\" equals 1, when a patient has cardiovascular disease, and it's 0 if a patient is healthy. Notice that this feature 'cardio' does not have any missing data. Had there been any missing values in the target feature, then the corresponding patient records must be dropped."
      ],
      "metadata": {
        "id": "3Flaa0g1t8Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['cardio'], inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "DxzRXmS6vgwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected no record is dropped."
      ],
      "metadata": {
        "id": "gkCG-_WhvqLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'weight' feature**"
      ],
      "metadata": {
        "id": "0k95ZG5iR6U_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the patients' records with 'weight' feature is NaN"
      ],
      "metadata": {
        "id": "s16fIXMr9E2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.weight.isnull()]"
      ],
      "metadata": {
        "id": "YccgPbZd8joO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the patients' records with 'weight' feature is not NaN"
      ],
      "metadata": {
        "id": "HMkKTbji_ReS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.weight.notna()]"
      ],
      "metadata": {
        "id": "30v15gys_LAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete (drop) records with 'weight' feature is NaN be selecting only rows with weight does not equal to NaN."
      ],
      "metadata": {
        "id": "vuHfhyW49iGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['weight'], inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "lccy3XFt-ExP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "zJlPXA_M_3W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed the number of records in the data frame was reduced by 4 (69996) and there is no NAN value in the 'weight' feature"
      ],
      "metadata": {
        "id": "G6XLHFzg_nzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'ap_hi', ap_lo', and 'gluc' features**"
      ],
      "metadata": {
        "id": "GEAvVchuSLfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will do the same for the 'ap_hi', ap_lo', and 'gluc' features."
      ],
      "metadata": {
        "id": "71x2ZqHwAICj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['ap_hi','ap_lo','gluc'], inplace=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "Sl6g9LCYETkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "0t7xluvsAf7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'gender' feature**"
      ],
      "metadata": {
        "id": "ujzyliWPgrt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gender feature is a string 'male, female' and we have many missing values. One option is to drop all records with 'gender' feature equals to 'NaN'. However this means dropping ~1.4% of the records and this is to be decided by the domain experts."
      ],
      "metadata": {
        "id": "tF97qFWPAiJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfgender = df.copy()\n",
        "print(dfgender.isnull()['gender'].sum())\n",
        "print(100*dfgender.isnull()['gender'].sum()/dfgender.shape[0],'%')\n",
        "print(dfgender.shape)\n",
        "dfgender.dropna(subset=['gender'], inplace=True)\n",
        "print(dfgender.shape)"
      ],
      "metadata": {
        "id": "8cRP3C98MZ5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another option is to replace all missing values in the 'gender' feature with the majority kind (male or female)."
      ],
      "metadata": {
        "id": "UvStd2oDMNtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['gender'].value_counts()"
      ],
      "metadata": {
        "id": "DIkCAEnaE8_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfc = df.copy()\n",
        "dfc['gender'].fillna(value='female', inplace=True)\n",
        "dfc['gender'].value_counts()"
      ],
      "metadata": {
        "id": "p-sA6WN9G28A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed the number of female records increased.\n",
        "\n",
        "A third option is to try to set the missing 'gender' feature values based on other values in the record. For example, we can check the correlation between 'gender' and 'height' features."
      ],
      "metadata": {
        "id": "r71taUcbH7ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['gender','height']].apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "76op9QTUI0-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that there is not much correlation. Let us try to check with other features."
      ],
      "metadata": {
        "id": "QUJx5LrmJci2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "Xd8ivdnyJHK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that the 'gender' feature has the highest correlation with the 'smoke' feature."
      ],
      "metadata": {
        "id": "Iyp4JAO_Jk_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[['gender','smoke']].apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "UOd5-ASKJ5MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us explore the correlation using crosstab"
      ],
      "metadata": {
        "id": "gETDiuhmJ7lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['gender'],df['smoke'])"
      ],
      "metadata": {
        "id": "wZBfYsOzKL7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This implies that most non-smokers are females and most smokers are males in the dataset. So let us make all 'gender' feature with 'NaN values for smokers to be 'male', and all 'gender' feature with 'NaN values for non-smokers to be 'female'."
      ],
      "metadata": {
        "id": "DrGH9VvELDy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfsmoke = df.copy()\n",
        "dfsmoke.loc[(dfsmoke.gender.isnull()) & (dfsmoke['smoke'] == 'Yes'),'gender']='male'\n",
        "dfsmoke.loc[(dfsmoke.gender.isnull()) & (dfsmoke['smoke'] == 'No'),'gender']='female'"
      ],
      "metadata": {
        "id": "7Ui91Kl4Ga5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check the correlation using crosstab again."
      ],
      "metadata": {
        "id": "3d4x5EC6KBhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(dfsmoke['gender'],dfsmoke['smoke'])"
      ],
      "metadata": {
        "id": "CvrUG87qJfFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the number of female non-smokers increased and the male smokers increase also. We also need to check if there are still any 'NaN' values in the 'gender' feature. This could be because the 'smoke' feature has also NaN values."
      ],
      "metadata": {
        "id": "M9dtZGEnKR5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfsmoke.isnull().sum()"
      ],
      "metadata": {
        "id": "2nGaE1DnKXiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 12 NaN values in the 'gender' feature. We will drop them because they make only very small percentage of the population (records in the dataset)."
      ],
      "metadata": {
        "id": "cwgjTHJ8K3sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dfsmoke.shape)\n",
        "dfsmoke.dropna(subset=['gender'], inplace=True)\n",
        "print(dfsmoke.shape)"
      ],
      "metadata": {
        "id": "vpuLXKQ2LLF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will consider the third option to deal with the 'NaN' values in the 'gender' feature."
      ],
      "metadata": {
        "id": "CGKuv5uKKcPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = dfsmoke.copy()\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "hY640BNhRbQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'smoke' feature**"
      ],
      "metadata": {
        "id": "HgD-mEXqUnPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now handle the missing vlues of the 'smoke' feature. This feature takes only two values 'Yes' and 'No'. Is there any correlation with the other features?"
      ],
      "metadata": {
        "id": "Mplvu1AVUqYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "QbmXcNmbUtvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is a high correlation between the 'smoke' feature and both the 'gender' and 'alco' features. But since we already used the 'smoke' feature to deal with the NaN values in the 'gender' feature and thus the correlation between them might be affected, we will use the 'alco' feature to deal with the NaN values in the 'smoke' feature."
      ],
      "metadata": {
        "id": "M4LjDwN8VH-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['smoke'],df['alco'])"
      ],
      "metadata": {
        "id": "Yj-m0YaxVuMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe from the crosstab results that most non-alcoholic persons in the dataset are non-smokers but alcoholic persons might or might not be smokers. So we will make all 'NaN' values in the 'smoke' feature for all records of non-alcoholic persons to be No."
      ],
      "metadata": {
        "id": "RFRA_nnyV3n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[(df.smoke.isnull()) & (df['alco'] == 0.0),'smoke']='No'"
      ],
      "metadata": {
        "id": "fhoNXlGxW09c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us check the correlation using crosstab again."
      ],
      "metadata": {
        "id": "7fIW1s1QXYkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['smoke'],df['alco'])"
      ],
      "metadata": {
        "id": "PhEgjpcLXT0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the number of non-alcoholic persons in the dataset is non-smokers increased. Let us know check the status of the missing values."
      ],
      "metadata": {
        "id": "M-wz1ZDFXc1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "s5Pd1xe2gqCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the number of remaining missing values of the 'smoke' feature is small, we will drop all other records with the 'smoke' feature equal to NaN."
      ],
      "metadata": {
        "id": "NVWKG8Lpg5_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['smoke'], inplace=True)\n",
        "print(df.shape)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "gN8zCQigZoVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'cholesterol' feature**"
      ],
      "metadata": {
        "id": "V6_acJYAaphM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now handle the missing vlues of the 'cholesterol' feature. This feature takes three values."
      ],
      "metadata": {
        "id": "utfT8QTIas0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.cholesterol.unique()"
      ],
      "metadata": {
        "id": "yWYnuKmca_gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Is there any correlation with the other features?"
      ],
      "metadata": {
        "id": "nIXSGF2fbL_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "-f4IeLNObKSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is a high correlation between the 'alco' feature and the 'gluc' feature. Let us explore the correlation using crosstab."
      ],
      "metadata": {
        "id": "2UDoMOh7bVIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(pd.crosstab(df['cholesterol'],df['gluc'])/pd.crosstab(df['cholesterol'],df['gluc']).sum())*100"
      ],
      "metadata": {
        "id": "7Tzol3MCb8TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that 81% of the persons with a 'gluc' value of 1.0 has also a 'cholesterol' value of 1.0. We also observe that 65% of the persons with a 'gluc' value of 3.0 has also a 'cholesterol' value of 3.0. And thus we will use these two notes to handle missing values of the 'cholesterol' feature. However, for the persons with a 'gluc' value of 2.0, 43% and 46% have 'cholesterol values of 1.0 and 2.0 which imply that we can not use the 'gluc' value for these persons to handle missing 'cholesterol' values."
      ],
      "metadata": {
        "id": "xfmW1kbscCHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[(df.cholesterol.isnull()) & (df['gluc'] == 1.0),'cholesterol']=1.0\n",
        "df.loc[(df.cholesterol.isnull()) & (df['gluc'] == 3.0),'cholesterol']=3.0"
      ],
      "metadata": {
        "id": "MKrvsUBzeV0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now check the status of missing values"
      ],
      "metadata": {
        "id": "O4Mz0gzKfOwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "i1x4ZN6UfMwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the number of missing values in the 'cholesterol' feature is reduced to 39. Then we will remove these records from the dataset."
      ],
      "metadata": {
        "id": "8pK4Gw0DfYRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df.dropna(subset=['cholesterol'], inplace=True)\n",
        "print(df.shape)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "_VZbICsKfo59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning: 'height' feature**"
      ],
      "metadata": {
        "id": "03DDV6d-Sko4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, for the 'height' feature, is there any correlation with the other features?"
      ],
      "metadata": {
        "id": "Evd_QkGKSwk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(lambda x: x.factorize()[0]).corr()"
      ],
      "metadata": {
        "id": "r0Eu30f9S_KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is a high correlation between the 'height' feature and both the 'gender' and 'weight' features. However, the 'height' feature has a continuous value and we can not deal with it similar to the 'gender' feature'. Instead, we should create a model that predicts the 'height' feature based on the 'gender' and 'weight' features which we will study in the next modules. So, for now, we have two options, either to drop all records where the 'height' feature is NaN or replace all these NaN values with some statistical measure (mean, median) of the 'height' feature. In this notebook, we will replace the NaN values with the median of the values in the 'height' feature."
      ],
      "metadata": {
        "id": "THhi8dlWTdrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.height.median())\n",
        "df['height'].fillna(df.height.median(), inplace=True)\n",
        "print(df.height.median())\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "E5mwkPkPUWxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove Outliers"
      ],
      "metadata": {
        "id": "SxMxobhoAPA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us have a close look at the statistical properties of the numaric features"
      ],
      "metadata": {
        "id": "xlI-m0y_AVxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "uVxi4Ql9Amfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, the 'id' feature will not have outliers, so let us check the 'age' feature. According to the description of the dataset, the age is in days. Let us convert the Age into years so that it is easier to understand and interpret."
      ],
      "metadata": {
        "id": "Dam4xa7eB0LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['age_years'] = (df['age'] / 365).round().astype('int')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Nb1hkh1SEVkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us have a close look again at the statistical properties of the numaric features"
      ],
      "metadata": {
        "id": "NPNvRQS3EijG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "q8tHIQa_BpSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The minimum age in the datset is about 30 years, the maximum is about 65 years, and the average is about 53.33 years."
      ],
      "metadata": {
        "id": "r90Je8pECGWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Outliers: 'height' and 'weight' feature**\n",
        "\n",
        "Next, let us examine the 'height' feature, the minimum height is 55cm which is too short for the records of persons with a minimum age of 30. Similarly, the maximum height is 250cms which is too rare value for a person's height. So there must be an error in the height feature. Let us also examine the 'weight' feature. The minimum weight is 10 kg which is too low for the records of persons with a minimum age of 30. So again, there must be an error in the 'weight' feature. Let us get the box plot of these two features."
      ],
      "metadata": {
        "id": "lCse5NWlCn2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 10, 6\n",
        "df.boxplot(column=['height', 'weight'])"
      ],
      "metadata": {
        "id": "IkRa_lWqD98-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed there are outliers, so let us remove weights and heights, that fall below 5% or above 95% of a given range."
      ],
      "metadata": {
        "id": "dF-eZV9gGSKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df[(df['height'] > df['height'].quantile(0.95)) | (df['height'] < df['height'].quantile(0.05))].index,inplace=True)\n",
        "df.drop(df[(df['weight'] > df['weight'].quantile(0.95)) | (df['weight'] < df['weight'].quantile(0.05))].index,inplace=True)"
      ],
      "metadata": {
        "id": "pGyRMYGUGfpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us get the box plot of these two features again."
      ],
      "metadata": {
        "id": "Y8vVtct3HBQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 10, 6\n",
        "df.boxplot(column=['height', 'weight'])"
      ],
      "metadata": {
        "id": "loJ7zofRHAhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed, the outliers for the 'height' and 'weight' features are removed."
      ],
      "metadata": {
        "id": "BbgbNWFXA-tS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Outliers: 'ap_hi' and 'ap_lo' feature**\n",
        "\n",
        "Similarly, we will do the same for the 'ap_hi' and 'ap_lo' features especially since the blood pressure can not be negative. Below is the box plot for the 'ap_hi' and 'ap_lo' features."
      ],
      "metadata": {
        "id": "BducBqYizknF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 10, 6\n",
        "df.boxplot(column=['ap_hi', 'ap_lo'])"
      ],
      "metadata": {
        "id": "1QEKFWT0vy8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will remove 'ap_hi' and 'ap_hi' features that fall below 5% or above 95% of a given range."
      ],
      "metadata": {
        "id": "ldRDsrTHyy2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(df[(df['ap_hi'] > df['ap_hi'].quantile(0.95)) | (df['ap_hi'] < df['ap_hi'].quantile(0.05))].index,inplace=True)\n",
        "df.drop(df[(df['ap_lo'] > df['ap_lo'].quantile(0.95)) | (df['ap_lo'] < df['ap_lo'].quantile(0.05))].index,inplace=True)"
      ],
      "metadata": {
        "id": "rhK8t4NRyXez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we plot again the box plot of the 'ap_hi' and 'ap_lo' features."
      ],
      "metadata": {
        "id": "luo39o09zAo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 10, 6\n",
        "df.boxplot(column=['ap_hi', 'ap_lo'])"
      ],
      "metadata": {
        "id": "l3xkRLK5wSho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be observed, the outliers for the 'height' and 'weight' features are removed. Let us also make sure that the systolic pressure 'ap_hi' is always higher than the diastolic pressure 'ap_lo'."
      ],
      "metadata": {
        "id": "p3GLdpeK1REj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Systolic pressure is higher than diastolic pressure in {0}% of the patient records\".format(100*df[df['ap_hi']> df['ap_lo']].shape[0]/df.shape[0]))"
      ],
      "metadata": {
        "id": "DrSfsZtB1PJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remove Outliers: the other features**\n",
        "\n",
        "The values of the other features are limited within a small range as can be observed from the min and max values in the statistical description table. Let us check if these features take only discrete values."
      ],
      "metadata": {
        "id": "zMr1aNHm4nnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('The discrete values of the \\'cholesterol\\' feature are {}'.format(set(df['cholesterol'].unique())))\n",
        "print('The discrete values of the \\'gluc\\' feature are {}'.format(set(df['gluc'].unique())))\n",
        "print('The discrete values of the \\'active\\' feature are {}'.format(set(df['active'].unique())))"
      ],
      "metadata": {
        "id": "TQIsmK525qF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the range of the other features is limited and the values are discrete so no need to apply outliers removal techniques for these features."
      ],
      "metadata": {
        "id": "EQwnJRgA7LAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Data"
      ],
      "metadata": {
        "id": "-SEz47bidar5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will save the clean dataset into a CSV file to be used in the next session."
      ],
      "metadata": {
        "id": "boXoDJ1hdfQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"/content/AIData/cardio_train_cleaned.csv\",sep=\";\",index=False)"
      ],
      "metadata": {
        "id": "sgb3CQnGd9il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the '/content/AIData/' folder for the 'cardio_train_cleaned.csv' file and download it for future usage."
      ],
      "metadata": {
        "id": "itbI0J9ZeKPB"
      }
    }
  ]
}